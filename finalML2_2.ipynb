{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiDPrI7Mntmw",
        "outputId": "1d6fd0b0-e274-435e-cb87-e756966d4288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG16"
      ],
      "metadata": {
        "id": "x4d1_TYSMYvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = (5250 // 32) + 1\n",
        "validation_steps = (624 // 32) + 1\n",
        "\n",
        "# Load the VGG16 model, excluding the top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of VGG16\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('my_vgg16_binary_classification_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd6-zEiLnvzE",
        "outputId": "d1b2c41b-1d54-4760-a6fe-a62fe3e0cd69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5250 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "165/165 [==============================] - 717s 4s/step - loss: 0.3082 - accuracy: 0.8859 - val_loss: 0.2173 - val_accuracy: 0.9231\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 110s 664ms/step - loss: 0.1793 - accuracy: 0.9312 - val_loss: 0.1944 - val_accuracy: 0.9263\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 110s 665ms/step - loss: 0.1716 - accuracy: 0.9343 - val_loss: 0.1746 - val_accuracy: 0.9359\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 110s 668ms/step - loss: 0.1691 - accuracy: 0.9333 - val_loss: 0.2544 - val_accuracy: 0.8894\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 116s 704ms/step - loss: 0.1568 - accuracy: 0.9440 - val_loss: 0.1713 - val_accuracy: 0.9311\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 106s 641ms/step - loss: 0.1480 - accuracy: 0.9429 - val_loss: 0.1791 - val_accuracy: 0.9295\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 107s 648ms/step - loss: 0.1399 - accuracy: 0.9476 - val_loss: 0.2004 - val_accuracy: 0.9071\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 109s 664ms/step - loss: 0.1311 - accuracy: 0.9488 - val_loss: 0.1317 - val_accuracy: 0.9551\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 105s 640ms/step - loss: 0.1321 - accuracy: 0.9505 - val_loss: 0.1525 - val_accuracy: 0.9375\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 106s 640ms/step - loss: 0.1345 - accuracy: 0.9522 - val_loss: 0.1511 - val_accuracy: 0.9407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('my_vgg16_binary_classification_model.h5')\n",
        "\n",
        "# Data preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important to keep the order for calculating metrics\n",
        ")\n",
        "\n",
        "# Evaluate the model on test data\n",
        "y_pred_proba = model.predict(test_generator)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# True labels\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "W-18Pyd9Xy7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2296b9-0f25-4795-9d13-6b9dcaf8ef5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "20/20 [==============================] - 9s 431ms/step\n",
            "Accuracy: 0.9407051282051282\n",
            "Precision: 0.9379652605459057\n",
            "Recall: 0.9692307692307692\n",
            "F1 Score: 0.9533417402269861\n",
            "ROC-AUC Score: 0.9850646504492658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "8B_dIVH-whC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = (5250 // 32) + 1\n",
        "validation_steps = (624 // 32) + 1\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('my_binary_classification_model.h5')"
      ],
      "metadata": {
        "id": "51PFGTAowZ2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f41144-6752-4328-d165-9e05acb0384e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5250 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "165/165 [==============================] - 146s 640ms/step - loss: 0.4236 - accuracy: 0.8166 - val_loss: 0.2580 - val_accuracy: 0.8974\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 105s 636ms/step - loss: 0.2464 - accuracy: 0.9011 - val_loss: 0.2894 - val_accuracy: 0.8702\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 102s 618ms/step - loss: 0.2119 - accuracy: 0.9168 - val_loss: 0.3670 - val_accuracy: 0.8253\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 103s 623ms/step - loss: 0.2053 - accuracy: 0.9223 - val_loss: 0.2372 - val_accuracy: 0.8910\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 109s 664ms/step - loss: 0.1739 - accuracy: 0.9303 - val_loss: 0.1543 - val_accuracy: 0.9599\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 101s 611ms/step - loss: 0.1761 - accuracy: 0.9307 - val_loss: 0.2353 - val_accuracy: 0.8926\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 106s 641ms/step - loss: 0.1560 - accuracy: 0.9398 - val_loss: 0.2872 - val_accuracy: 0.8766\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 106s 644ms/step - loss: 0.1470 - accuracy: 0.9423 - val_loss: 0.2153 - val_accuracy: 0.9087\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 104s 631ms/step - loss: 0.1469 - accuracy: 0.9459 - val_loss: 0.1647 - val_accuracy: 0.9487\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 104s 633ms/step - loss: 0.1419 - accuracy: 0.9467 - val_loss: 0.1445 - val_accuracy: 0.9647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('my_binary_classification_model.h5')\n",
        "\n",
        "# Data preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important to keep the order for calculating metrics\n",
        ")\n",
        "\n",
        "# Evaluate the model on test data\n",
        "y_pred_proba = model.predict(test_generator)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# True labels\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "zlwVkuV-Wj73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc56a1f-190c-40d7-ac3b-1a569858eada"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "20/20 [==============================] - 8s 382ms/step\n",
            "Accuracy: 0.9647435897435898\n",
            "Precision: 0.9577114427860697\n",
            "Recall: 0.9871794871794872\n",
            "F1 Score: 0.9722222222222222\n",
            "ROC-AUC Score: 0.9877492877492877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet-101"
      ],
      "metadata": {
        "id": "kFegi67I1LHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = (5250 // 32) + 1\n",
        "validation_steps = (624 // 32) + 1\n",
        "\n",
        "# Load ResNet-101 with pre-trained weights and without the top layer\n",
        "base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add new layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Construct the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('my_binary_classification_model_resnet101.h5')"
      ],
      "metadata": {
        "id": "D20alsuF1C8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dbfa8d-c349-4a0d-a641-de39f9c7d56f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5250 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171446536/171446536 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "165/165 [==============================] - 160s 657ms/step - loss: 0.5895 - accuracy: 0.7196 - val_loss: 0.6564 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 105s 638ms/step - loss: 0.5411 - accuracy: 0.7419 - val_loss: 0.6047 - val_accuracy: 0.6378\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 105s 638ms/step - loss: 0.5153 - accuracy: 0.7470 - val_loss: 0.5853 - val_accuracy: 0.6571\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 111s 671ms/step - loss: 0.5009 - accuracy: 0.7528 - val_loss: 0.5585 - val_accuracy: 0.6779\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 105s 633ms/step - loss: 0.4834 - accuracy: 0.7617 - val_loss: 0.5528 - val_accuracy: 0.6859\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 114s 688ms/step - loss: 0.4656 - accuracy: 0.7697 - val_loss: 0.5299 - val_accuracy: 0.7067\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 106s 643ms/step - loss: 0.4520 - accuracy: 0.7766 - val_loss: 0.5288 - val_accuracy: 0.7051\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 106s 641ms/step - loss: 0.4394 - accuracy: 0.7815 - val_loss: 0.5186 - val_accuracy: 0.7099\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 105s 637ms/step - loss: 0.4270 - accuracy: 0.7888 - val_loss: 0.4917 - val_accuracy: 0.7452\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 110s 668ms/step - loss: 0.4190 - accuracy: 0.7998 - val_loss: 0.5061 - val_accuracy: 0.7147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('my_binary_classification_model_resnet101.h5')\n",
        "\n",
        "# Data preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important to keep the order for calculating metrics\n",
        ")\n",
        "\n",
        "# Evaluate the model on test data\n",
        "y_pred_proba = model.predict(test_generator)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# True labels\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "nhseuOC8jxFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9d28b2-0b02-40d8-c419-2f33da18f7cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "20/20 [==============================] - 11s 436ms/step\n",
            "Accuracy: 0.7147435897435898\n",
            "Precision: 0.6955719557195572\n",
            "Recall: 0.9666666666666667\n",
            "F1 Score: 0.8090128755364808\n",
            "ROC-AUC Score: 0.871356563664256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Denese Net 121"
      ],
      "metadata": {
        "id": "WNt29gk3xCyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = (5250 // 32) + 1\n",
        "validation_steps = (624 // 32) + 1\n",
        "\n",
        "# Load the DenseNet121 model, excluding the top layers\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of DenseNet121\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('my_densenet121_binary_classification_model.h5')\n"
      ],
      "metadata": {
        "id": "qSjePQ_1w8Xc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662ae4a3-0beb-4e99-e7eb-0e63aaf74f3d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5250 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "165/165 [==============================] - 129s 660ms/step - loss: 0.8952 - accuracy: 0.8775 - val_loss: 0.3791 - val_accuracy: 0.8301\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 112s 679ms/step - loss: 0.1916 - accuracy: 0.9213 - val_loss: 0.2214 - val_accuracy: 0.9087\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 111s 675ms/step - loss: 0.1882 - accuracy: 0.9301 - val_loss: 0.1992 - val_accuracy: 0.9183\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 103s 622ms/step - loss: 0.1885 - accuracy: 0.9259 - val_loss: 0.1967 - val_accuracy: 0.9167\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 108s 657ms/step - loss: 0.1856 - accuracy: 0.9242 - val_loss: 0.1817 - val_accuracy: 0.9247\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 113s 685ms/step - loss: 0.1689 - accuracy: 0.9373 - val_loss: 0.1964 - val_accuracy: 0.9199\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 116s 703ms/step - loss: 0.1713 - accuracy: 0.9383 - val_loss: 0.1941 - val_accuracy: 0.9087\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 111s 674ms/step - loss: 0.1669 - accuracy: 0.9377 - val_loss: 0.1702 - val_accuracy: 0.9327\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 110s 665ms/step - loss: 0.1620 - accuracy: 0.9411 - val_loss: 0.2010 - val_accuracy: 0.9231\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 115s 698ms/step - loss: 0.1492 - accuracy: 0.9459 - val_loss: 0.1608 - val_accuracy: 0.9359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('my_densenet121_binary_classification_model.h5')\n",
        "\n",
        "# Data preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important to keep the order for calculating metrics\n",
        ")\n",
        "\n",
        "# Evaluate the model on test data\n",
        "y_pred_proba = model.predict(test_generator)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# True labels\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "OF2hmzsTYISr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9af1cc-0962-46b0-9039-0c16d4e4d5bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "20/20 [==============================] - 11s 439ms/step\n",
            "Accuracy: 0.9358974358974359\n",
            "Precision: 0.9310344827586207\n",
            "Recall: 0.9692307692307692\n",
            "F1 Score: 0.949748743718593\n",
            "ROC-AUC Score: 0.9847797501643656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mobile"
      ],
      "metadata": {
        "id": "9nClhklZYfHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = (5250 // 32) + 1\n",
        "validation_steps = (624 // 32) + 1\n",
        "\n",
        "# Load MobileNetV2 with pre-trained weights and without the top layer\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add new layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Construct the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('my_mobile_classification_model_mobilenetv2.h5')\n"
      ],
      "metadata": {
        "id": "lOqo9YbnYi0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cee668-3c41-4957-8499-acff1baccb3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5250 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "165/165 [==============================] - 114s 669ms/step - loss: 0.3855 - accuracy: 0.8411 - val_loss: 0.3735 - val_accuracy: 0.8526\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 106s 641ms/step - loss: 0.2234 - accuracy: 0.9088 - val_loss: 0.2830 - val_accuracy: 0.8878\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 100s 608ms/step - loss: 0.1967 - accuracy: 0.9234 - val_loss: 0.2480 - val_accuracy: 0.9054\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 102s 615ms/step - loss: 0.1794 - accuracy: 0.9288 - val_loss: 0.2990 - val_accuracy: 0.8830\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 101s 614ms/step - loss: 0.1667 - accuracy: 0.9341 - val_loss: 0.2846 - val_accuracy: 0.8894\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 101s 609ms/step - loss: 0.1645 - accuracy: 0.9354 - val_loss: 0.2661 - val_accuracy: 0.8910\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 103s 626ms/step - loss: 0.1484 - accuracy: 0.9411 - val_loss: 0.2498 - val_accuracy: 0.9103\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 101s 613ms/step - loss: 0.1631 - accuracy: 0.9349 - val_loss: 0.2529 - val_accuracy: 0.9103\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 111s 672ms/step - loss: 0.1586 - accuracy: 0.9360 - val_loss: 0.2329 - val_accuracy: 0.9167\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 100s 606ms/step - loss: 0.1471 - accuracy: 0.9444 - val_loss: 0.2941 - val_accuracy: 0.8942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('my_mobile_classification_model_mobilenetv2.h5')\n",
        "\n",
        "# Data preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/ML_DATA/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important to keep the order for calculating metrics\n",
        ")\n",
        "\n",
        "# Evaluate the model on test data\n",
        "y_pred_proba = model.predict(test_generator)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# True labels\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "veKySU7biss_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd60c64-8e88-423a-b137-2f1345b93ce2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 images belonging to 2 classes.\n",
            "20/20 [==============================] - 9s 417ms/step\n",
            "Accuracy: 0.8942307692307693\n",
            "Precision: 0.8732718894009217\n",
            "Recall: 0.9717948717948718\n",
            "F1 Score: 0.9199029126213591\n",
            "ROC-AUC Score: 0.9672802980495288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GUI"
      ],
      "metadata": {
        "id": "Vuq4s0yHxZ1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gradio"
      ],
      "metadata": {
        "id": "oWKs3TCfOwhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f966c055-4bfa-4ee9-a226-f00af231d1ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.31.4-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.4 (from gradio)\n",
            "  Downloading gradio_client-0.16.4-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.4->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=4db158343f312747e160c8c6c9f6a4e360495eeec89d23cc3dad96890ca61531\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.31.4 gradio-client-0.16.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.4 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "TSV98vHVxk4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290d4f59-5b80-4681-e990-418326d3bff9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.31.4)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.16.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.16.4)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.4)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.1.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Define the available models and their paths\n",
        "model_paths = {\n",
        "    \"CNN\": \"my_binary_classification_model.h5\",\n",
        "    \"VGG16\": \"my_vgg16_binary_classification_model.h5\",\n",
        "    \"DenseNet121 \": \"my_densenet121_binary_classification_model.h5\",\n",
        "    \"MobileNetV2\":\"my_mobile_classification_model_mobilenetv2.h5\",\n",
        "    \"ResNet101\":\"my_binary_classification_model_resnet101.h5\"\n",
        "}\n",
        "\n",
        "# Load a model based on the selected path\n",
        "def load_model(model_name):\n",
        "    return tf.keras.models.load_model(model_paths[model_name])\n",
        "\n",
        "# Define the function to make predictions\n",
        "def predict_pneumonia(model_name, img):\n",
        "  if model_name ==\"MobileNetV2\":\n",
        "    model = load_model(model_name)  # Load the selected model\n",
        "    img = img.resize((224, 224))  # Resize the image to the expected input size\n",
        "    img_array = image.img_to_array(img)  # Convert image to array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Rescale the image\n",
        "  else:\n",
        "    model = load_model(model_name)  # Load the selected model\n",
        "    img = img.resize((150, 150))  # Resize the image to the expected input size\n",
        "    img_array = image.img_to_array(img)  # Convert image to array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Rescale the image\n",
        "\n",
        "  prediction = model.predict(img_array)  # Make prediction\n",
        "  if prediction[0] > 0.5:\n",
        "     return \"Pneumonia\"\n",
        "  else:\n",
        "     return \"Normal\"\n",
        "\n",
        "# Create Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=predict_pneumonia,\n",
        "    inputs=[\n",
        "        gr.Dropdown(choices=list(model_paths.keys()), label=\"Select Model\"),  # Dropdown for model selection\n",
        "        gr.Image(type=\"pil\", label=\"Upload X-ray Image\")  # Image upload\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Prediction\")  # Output textbox\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "6liu_CK5xYtv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "3dc4fa83-36e0-41f6-b47d-6449a96cd6af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://988f6cbc62aa3c574f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://988f6cbc62aa3c574f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}